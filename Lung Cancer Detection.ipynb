{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dd6ZbK6d0tI"
      },
      "source": [
        "# **CNN with KFold**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ny7zb7ZcicK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", message=\".*Tracing is expensive.*\")\n",
        "\n",
        "# Function to load images from a folder\n",
        "def load_images_from_folder(folder, label, target_size=(100, 100)):\n",
        "    # Check if the folder exists before proceeding\n",
        "    if not os.path.exists(folder):\n",
        "        raise FileNotFoundError(f\"Folder not found: {folder}\")  # Raise a clear error if the folder doesn't exist\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = Image.open(os.path.join(folder, filename)).convert('L')  # Convert to grayscale\n",
        "        if img is not None:\n",
        "            img = img.resize(target_size)  # Resize the image to a fixed size\n",
        "            img = np.array(img)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "# Define the paths to the folders\n",
        "benign_folder = '/content/drive/MyDrive/lung_cancer_model/Benign'\n",
        "malignant_folder = '/content/drive/MyDrive/lung_cancer_model/Malignant'\n",
        "adenocarcinoma_folder = '/content/drive/MyDrive/lung_cancer_model/Adenocarcinoma'\n",
        "large_cell_carcinoma_folder = '/content/drive/MyDrive/lung_cancer_model/Large.Cell.Carcinoma'\n",
        "normal_folder = '/content/drive/MyDrive/lung_cancer_model/Normal'\n",
        "squamous_cell_carcinoma_folder = '/content/drive/MyDrive/lung_cancer_model/Squamous.Cell.Carcinoma'\n",
        "\n",
        "# Load images and labels for each category\n",
        "benign_images, benign_labels = load_images_from_folder(benign_folder, 0)\n",
        "malignant_images, malignant_labels = load_images_from_folder(malignant_folder, 1)\n",
        "adenocarcinoma_images, adenocarcinoma_labels = load_images_from_folder(adenocarcinoma_folder, 2)\n",
        "large_cell_carcinoma_images, large_cell_carcinoma_labels = load_images_from_folder(large_cell_carcinoma_folder, 3)\n",
        "normal_images, normal_labels = load_images_from_folder(normal_folder, 4)\n",
        "squamous_cell_carcinoma_images, squamous_cell_carcinoma_labels = load_images_from_folder(squamous_cell_carcinoma_folder, 5)\n",
        "\n",
        "# Concatenate the images and labels from all categories\n",
        "images = np.concatenate([benign_images, malignant_images, adenocarcinoma_images, large_cell_carcinoma_images, normal_images, squamous_cell_carcinoma_images], axis=0)\n",
        "labels = np.concatenate([benign_labels, malignant_labels, adenocarcinoma_labels, large_cell_carcinoma_labels, normal_labels, squamous_cell_carcinoma_labels], axis=0)\n",
        "\n",
        "# Normalize the pixel values to range [0, 1]\n",
        "images = images / 255.0\n",
        "\n",
        "# Reshape the input data to fit the CNN input shape (assuming grayscale images)\n",
        "height, width = images[0].shape\n",
        "images = images.reshape((-1, height, width, 1))\n",
        "\n",
        "# Define the number of folds\n",
        "n_splits = 16\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "train_accuracy = []\n",
        "train_loss = []\n",
        "val_accuracy = []\n",
        "val_loss = []\n",
        "\n",
        "# Initialize lists to store true and predicted labels for all folds\n",
        "all_true_labels = []\n",
        "all_predicted_labels = []\n",
        "\n",
        "# Iterate over the splits\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(images)):\n",
        "    print(f\"Fold {fold+1}/{n_splits}\")\n",
        "\n",
        "    # Split the dataset into training and testing sets for this fold\n",
        "    X_train, X_test = images[train_index], images[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "# Define data augmentation\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        layers.RandomRotation(0.2),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ])\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, 1), kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(6, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    # Preprocess training data with data augmentation\n",
        "    X_train = data_augmentation(X_train)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=40, batch_size=64, validation_split=0.1, verbose=1,\n",
        "                        callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions_prob = model.predict(X_test)\n",
        "    predictions = np.argmax(predictions_prob, axis=1)\n",
        "\n",
        "    # Append true and predicted labels for this fold\n",
        "    all_true_labels.extend(y_test)\n",
        "    all_predicted_labels.extend(predictions)\n",
        "\n",
        "    train_accuracy.append(history.history['accuracy'])\n",
        "    train_loss.append(history.history['loss'])\n",
        "    val_accuracy.append(history.history['val_accuracy'])\n",
        "    val_loss.append(history.history['val_loss'])\n",
        "\n",
        "# Add VGG16 model for comparison\n",
        "print(\"\\nEvaluating VGG16 model\")\n",
        "\n",
        "# Load VGG16 base model\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(height, width, 3))\n",
        "vgg16_base.trainable = False\n",
        "\n",
        "# Prepare RGB images for VGG16\n",
        "images_rgb = np.repeat(images, 3, axis=-1)  # Convert grayscale to RGB\n",
        "\n",
        "# Iterate over the splits for VGG16\n",
        "vgg16_true_labels = []\n",
        "vgg16_predicted_labels = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(images_rgb)):\n",
        "    print(f\"VGG16 Fold {fold+1}/{n_splits}\")\n",
        "\n",
        "    # Split the dataset into training and testing sets for this fold\n",
        "    X_train, X_test = images_rgb[train_index], images_rgb[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    # Define the VGG16-based model\n",
        "    vgg16_model = models.Sequential([\n",
        "        vgg16_base,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(6, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the VGG16 model\n",
        "    vgg16_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "    # Train the VGG16 model\n",
        "    vgg16_model.fit(X_train, y_train, epochs=40, batch_size=64, validation_split=0.1, verbose=1)\n",
        "\n",
        "    # Evaluate the VGG16 model on test data\n",
        "    vgg16_test_loss, vgg16_test_accuracy = vgg16_model.evaluate(X_test, y_test)\n",
        "    print(f\"VGG16 Fold {fold+1} Accuracy: {vgg16_test_accuracy*100:.2f}%\")\n",
        "\n",
        "    # Make predictions\n",
        "    vgg16_predictions_prob = vgg16_model.predict(X_test)\n",
        "    vgg16_predictions = np.argmax(vgg16_predictions_prob, axis=1)\n",
        "\n",
        "    # Append true and predicted labels for this fold\n",
        "    vgg16_true_labels.extend(y_test)\n",
        "    vgg16_predicted_labels.extend(vgg16_predictions)\n",
        "\n",
        "# Calculate VGG16 overall accuracy\n",
        "print(\"\\nVGG16 Classification Report:\")\n",
        "print(classification_report(vgg16_true_labels, vgg16_predicted_labels))\n",
        "\n",
        "print(\"VGG16 Confusion Matrix:\")\n",
        "vgg16_conf_matrix = confusion_matrix(vgg16_true_labels, vgg16_predicted_labels)\n",
        "sns.heatmap(vgg16_conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate overall accuracy\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_true_labels, all_predicted_labels))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMO2BxfyfXF3"
      },
      "source": [
        "# **DISTRIBUTION OF IMAGE CATEGORIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zet-F76CdmZ2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Get the maximum number of epochs across all folds\n",
        "max_epochs = max(len(acc) for acc in train_accuracy)\n",
        "\n",
        "# Pad shorter accuracy lists with NaN to make them equal length\n",
        "train_accuracy_padded = [acc + [np.nan] * (max_epochs - len(acc)) for acc in train_accuracy]\n",
        "val_accuracy_padded = [acc + [np.nan] * (max_epochs - len(acc)) for acc in val_accuracy]\n",
        "train_loss_padded = [loss + [np.nan] * (max_epochs - len(loss)) for loss in train_loss]\n",
        "val_loss_padded = [loss + [np.nan] * (max_epochs - len(loss)) for loss in val_loss]\n",
        "\n",
        "\n",
        "# Create the epochs range based on the maximum number of epochs\n",
        "epochs = range(max_epochs)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[0].plot(epochs, np.nanmean(train_accuracy_padded, axis=0), 'go-', label='Training Accuracy')\n",
        "ax[0].plot(epochs, np.nanmean(val_accuracy_padded, axis=0), 'ro-', label='Testing Accuracy')\n",
        "ax[0].set_title('Training & Testing Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[1].plot(epochs, np.nanmean(train_loss_padded, axis=0), 'g-o', label='Training Loss')\n",
        "ax[1].plot(epochs, np.nanmean(val_loss_padded, axis=0), 'r-o', label='Testing Loss')\n",
        "ax[1].set_title('Training & Testing Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQ-PJxDeCZx"
      },
      "source": [
        "# **IMAGES OF EACH CATEGORY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiW3-GyHdoV_"
      },
      "outputs": [],
      "source": [
        "print(\"Classification Report:\")\n",
        "\n",
        "# Specify the correct target names, matching the number of classes in your dataset\n",
        "target_names = ['Benign', 'Malignant', 'Adenocarcinoma', 'Large Cell Carcinoma', 'Normal', 'Squamous Cell Carcinoma']\n",
        "\n",
        "print(classification_report(all_true_labels, all_predicted_labels, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oiMEXYvdqMc"
      },
      "outputs": [],
      "source": [
        "# Find indices of correct predictions\n",
        "correct_indices = np.where(predictions == y_test)[0]\n",
        "\n",
        "# Define category names  (This line was added)\n",
        "category_names = ['Benign', 'Malignant', 'Adenocarcinoma','Large Cell Carcinoma','Normal', 'Squamous Cell Carcinoma']\n",
        "\n",
        "# Display correct predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.suptitle('Correctly Predicted Samples', fontsize=16)\n",
        "for i, idx in enumerate(correct_indices[:6]):\n",
        "    plt.subplot(3, 2, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    # Reshape to (height, width, 3) for RGB images\n",
        "    plt.imshow(X_test[idx].reshape(height, width, 3), interpolation='none')\n",
        "    plt.title(\"Predicted {}, Actual {}\".format(category_names[predictions[idx]], category_names[y_test[idx]]), fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rie8Jn1QdsHI"
      },
      "outputs": [],
      "source": [
        "# Find indices of incorrect predictions\n",
        "incorrect_indices = np.where(predictions != y_test)[0]\n",
        "\n",
        "# Display incorrect predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.suptitle('Incorrectly Predicted Samples', fontsize=16)\n",
        "for i, idx in enumerate(incorrect_indices[:6]):\n",
        "    plt.subplot(3, 2, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    # Reshape to (height, width, 3) for RGB images or (height, width) for grayscale\n",
        "    plt.imshow(X_test[idx].reshape(height, width, 3) if X_test[idx].shape[-1] == 3 else X_test[idx].reshape(height, width),\n",
        "               cmap=\"gray\" if X_test[idx].shape[-1] == 1 else None, interpolation='none')\n",
        "    plt.title(\"Predicted {}, Actual {}\".format(category_names[predictions[idx]], category_names[y_test[idx]]), fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpBUSMWpdw0X"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define category names\n",
        "category_names = ['Benign', 'Malignant', 'Adenocarcinoma','Large Cell Carcinoma','Normal', 'Squamous Cell Carcinoma']\n",
        "\n",
        "# Convert numeric labels to category names\n",
        "all_true_categories = [category_names[label] for label in all_true_labels]\n",
        "all_predicted_categories = [category_names[label] for label in all_predicted_labels]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_true_categories, all_predicted_categories, labels=category_names)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, xticklabels=category_names, yticklabels=category_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}